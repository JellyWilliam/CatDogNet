{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8228da4d-1104-41b8-ab38-58a481bfd650",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9acb361-3450-4dbc-bd03-bc68365e2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967ecf09-1b00-43a2-86f9-fdef4f4253d8",
   "metadata": {},
   "source": [
    "# Создание класса модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0d994d8-7f5d-4492-8cd5-fd363ead99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, num_class=2):\n",
    "        super(ImageClassifier, self).__init__()\n",
    "\n",
    "        # Сверточные слои для извлечения признаков\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Пакетная нормализация\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        # Функция активации ReLU\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Пулинг (уменьшение размерности)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Полносвязные слои для классификации\n",
    "        self.fc1 = nn.Linear(256 * 400, 256)\n",
    "        self.fc2 = nn.Linear(256, num_class) \n",
    "        \n",
    "        # Регуляризация \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Приравниваем размерности перед подачей в полносвязный слой\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e245df3e-8c48-4511-b8bf-579be0737512",
   "metadata": {},
   "source": [
    "# Инициализация датасета "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f2e91e8-969b-42d5-bf76-7adb631d5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((332, 332)),  # Изменение размера изображения\n",
    "    transforms.ToTensor(),  # Преобразование в тензор\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Нормализация данных\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root=\"D:\\ProjectsData\\Cats vs Dogs\\PetImages\", transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c586262-c0c7-47ec-a016-a9d7aafe7704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество наборов данных на:\n",
      "Обучение: 14998\n",
      "Валидацию: 5000\n",
      "Тестирование: 5000\n"
     ]
    }
   ],
   "source": [
    "len_dataset = len(dataset)\n",
    "train_size = int(len_dataset * 0.6)\n",
    "val_size = int((len_dataset - train_size) * 0.5)\n",
    "test_size = len_dataset - train_size - val_size\n",
    "\n",
    "print(f\"Количество наборов данных на:\\nОбучение: {train_size}\\nВалидацию: {val_size}\\nТестирование: {test_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c7d97b-dc02-4d36-a2d3-7bed453a5a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение датасета на обучение, валидацию и тестирование\n",
    "dataset_train, dataset_val, dataset_test = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a19091f-5e96-4163-b2d3-9c24d1fe97b3",
   "metadata": {},
   "source": [
    "# Инициализация загрузчика данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5c323fe-068a-4770-a9c0-337f85e4f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val)\n",
    "dataloader_test = DataLoader(dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739566f8-d475-44b2-be96-8743d8dcca9a",
   "metadata": {},
   "source": [
    "# Инициализация модели, функции потерь, оптимизатора и контроллера скорости обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21855f14-fda0-4c34-9ddf-caca112c03b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# Определение модели\n",
    "model = ImageClassifier(num_class=2)\n",
    "model.to(device)\n",
    "\n",
    "# Определение функции потерь и оптимизатора\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d321e97b-de1f-4bd8-a401-1b65bd11823e",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66138454-0938-491a-8462-64deb700c618",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in trange(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(dataloader_train):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "    train_loss = train_loss / len(dataset_train)\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    y_true, y_pred = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader_val):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item() * images.size(0)\n",
    "\n",
    "            predictions = outputs.argmax(dim=1)\n",
    "            \n",
    "            y_true.extend(labels.cpu())\n",
    "            y_pred.extend(predictions.cpu())\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "            lr = param_group['lr']\n",
    "    \n",
    "    scheduler.step()\n",
    "    valid_loss = valid_loss / len(dataset_val)\n",
    "    print(f\"Эпоха {epoch+1}/{num_epochs}\\nПотери при обучении: {train_loss:.4f}\\nПотери при валидации: {valid_loss:.4f}\\nСкорость обучения: {lr}\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    accuracy = f1_score(y_true, y_pred)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), \"cat_vs_dog_classifier_v1.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceda66c-a1c2-49ab-a722-02817d80ada8",
   "metadata": {},
   "source": [
    "# Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "547c58c4-aef9-4ac5-8194-58422ed02b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0e6d80ccc946de97ad6d241296c85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потери при тестировании: 0.3526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      2474\n",
      "           1       0.84      0.85      0.84      2526\n",
      "\n",
      "    accuracy                           0.84      5000\n",
      "   macro avg       0.84      0.84      0.84      5000\n",
      "weighted avg       0.84      0.84      0.84      5000\n",
      "\n",
      "[[2049  425]\n",
      " [ 372 2154]]\n"
     ]
    }
   ],
   "source": [
    "# Загрузка лучшей модели и оценка на тестовом наборе данных\n",
    "model.load_state_dict(torch.load(\"cat_vs_dog_classifier_v1.pt\"))\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(dataloader_test):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "\n",
    "        predictions = outputs.argmax(dim=1)\n",
    "        \n",
    "        y_true.extend(labels.cpu())\n",
    "        y_pred.extend(predictions.cpu())\n",
    "\n",
    "test_loss = test_loss / len(dataset_test)\n",
    "\n",
    "print(f\"Потери при тестировании: {test_loss:.4f}\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d673336-d675-4459-b063-1e9d9ab7d39b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
